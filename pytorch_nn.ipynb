{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9  ...  775  776  777  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       778  779  780  781  782  783  label  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0      5  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0      0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0      4  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0      1  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0      9  \n",
       "...    ...  ...  ...  ...  ...  ...    ...  \n",
       "69995  0.0  0.0  0.0  0.0  0.0  0.0      2  \n",
       "69996  0.0  0.0  0.0  0.0  0.0  0.0      3  \n",
       "69997  0.0  0.0  0.0  0.0  0.0  0.0      4  \n",
       "69998  0.0  0.0  0.0  0.0  0.0  0.0      5  \n",
       "69999  0.0  0.0  0.0  0.0  0.0  0.0      6  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data/mnist.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 30)\n",
    "        self.fc2 = torch.nn.Linear(30, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "model = SimpleNN().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 0.08947660028934479\n",
      "Epoch 11/1000, Loss: 0.07332063466310501\n",
      "Epoch 21/1000, Loss: 0.04989853501319885\n",
      "Epoch 31/1000, Loss: 0.03738477826118469\n",
      "Epoch 41/1000, Loss: 0.030177395790815353\n",
      "Epoch 51/1000, Loss: 0.025737041607499123\n",
      "Epoch 61/1000, Loss: 0.02285456843674183\n",
      "Epoch 71/1000, Loss: 0.020883508026599884\n",
      "Epoch 81/1000, Loss: 0.019444376230239868\n",
      "Epoch 91/1000, Loss: 0.01832912303507328\n",
      "Epoch 101/1000, Loss: 0.017424730584025383\n",
      "Epoch 111/1000, Loss: 0.016667388379573822\n",
      "Epoch 121/1000, Loss: 0.01601864956319332\n",
      "Epoch 131/1000, Loss: 0.01545366458594799\n",
      "Epoch 141/1000, Loss: 0.014955339953303337\n",
      "Epoch 151/1000, Loss: 0.014511357992887497\n",
      "Epoch 161/1000, Loss: 0.014112502336502075\n",
      "Epoch 171/1000, Loss: 0.013751687481999397\n",
      "Epoch 181/1000, Loss: 0.013423324562609196\n",
      "Epoch 191/1000, Loss: 0.0131229218095541\n",
      "Epoch 201/1000, Loss: 0.012846793979406357\n",
      "Epoch 211/1000, Loss: 0.012591885402798653\n",
      "Epoch 221/1000, Loss: 0.012355630286037922\n",
      "Epoch 231/1000, Loss: 0.012135853059589863\n",
      "Epoch 241/1000, Loss: 0.01193070225417614\n",
      "Epoch 251/1000, Loss: 0.011738590896129608\n",
      "Epoch 261/1000, Loss: 0.011558164842426777\n",
      "Epoch 271/1000, Loss: 0.01138825248926878\n",
      "Epoch 281/1000, Loss: 0.011227848939597607\n",
      "Epoch 291/1000, Loss: 0.011076082475483418\n",
      "Epoch 301/1000, Loss: 0.010932205244898796\n",
      "Epoch 311/1000, Loss: 0.010795559734106064\n",
      "Epoch 321/1000, Loss: 0.010665583424270153\n",
      "Epoch 331/1000, Loss: 0.01054177712649107\n",
      "Epoch 341/1000, Loss: 0.01042370405048132\n",
      "Epoch 351/1000, Loss: 0.010310972109436989\n",
      "Epoch 361/1000, Loss: 0.010203229263424873\n",
      "Epoch 371/1000, Loss: 0.010100150480866432\n",
      "Epoch 381/1000, Loss: 0.01000143587589264\n",
      "Epoch 391/1000, Loss: 0.009906803257763386\n",
      "Epoch 401/1000, Loss: 0.009815988130867481\n",
      "Epoch 411/1000, Loss: 0.009728736244142056\n",
      "Epoch 421/1000, Loss: 0.009644811041653156\n",
      "Epoch 431/1000, Loss: 0.009563986212015152\n",
      "Epoch 441/1000, Loss: 0.009486054070293903\n",
      "Epoch 451/1000, Loss: 0.009410813450813293\n",
      "Epoch 461/1000, Loss: 0.009338082745671272\n",
      "Epoch 471/1000, Loss: 0.00926769245415926\n",
      "Epoch 481/1000, Loss: 0.009199481457471848\n",
      "Epoch 491/1000, Loss: 0.009133304469287395\n",
      "Epoch 501/1000, Loss: 0.00906902551651001\n",
      "Epoch 511/1000, Loss: 0.009006517939269543\n",
      "Epoch 521/1000, Loss: 0.008945667184889317\n",
      "Epoch 531/1000, Loss: 0.008886365219950676\n",
      "Epoch 541/1000, Loss: 0.008828512392938137\n",
      "Epoch 551/1000, Loss: 0.008772015571594238\n",
      "Epoch 561/1000, Loss: 0.008716791868209839\n",
      "Epoch 571/1000, Loss: 0.008662758395075798\n",
      "Epoch 581/1000, Loss: 0.008609839715063572\n",
      "Epoch 591/1000, Loss: 0.008557966910302639\n",
      "Epoch 601/1000, Loss: 0.008507072925567627\n",
      "Epoch 611/1000, Loss: 0.008457094430923462\n",
      "Epoch 621/1000, Loss: 0.008407975547015667\n",
      "Epoch 631/1000, Loss: 0.008359663188457489\n",
      "Epoch 641/1000, Loss: 0.008312107063829899\n",
      "Epoch 651/1000, Loss: 0.008265268057584763\n",
      "Epoch 661/1000, Loss: 0.008219106122851372\n",
      "Epoch 671/1000, Loss: 0.008173590525984764\n",
      "Epoch 681/1000, Loss: 0.008128696121275425\n",
      "Epoch 691/1000, Loss: 0.008084405213594437\n",
      "Epoch 701/1000, Loss: 0.008040701039135456\n",
      "Epoch 711/1000, Loss: 0.007997577078640461\n",
      "Epoch 721/1000, Loss: 0.007955028675496578\n",
      "Epoch 731/1000, Loss: 0.007913054898381233\n",
      "Epoch 741/1000, Loss: 0.007871653884649277\n",
      "Epoch 751/1000, Loss: 0.007830832153558731\n",
      "Epoch 761/1000, Loss: 0.007790588773787022\n",
      "Epoch 771/1000, Loss: 0.0077509284019470215\n",
      "Epoch 781/1000, Loss: 0.007711851969361305\n",
      "Epoch 791/1000, Loss: 0.007673359476029873\n",
      "Epoch 801/1000, Loss: 0.007635445799678564\n",
      "Epoch 811/1000, Loss: 0.007598112337291241\n",
      "Epoch 821/1000, Loss: 0.007561350706964731\n",
      "Epoch 831/1000, Loss: 0.007525154855102301\n",
      "Epoch 841/1000, Loss: 0.0074895103462040424\n",
      "Epoch 851/1000, Loss: 0.007454414386302233\n",
      "Epoch 861/1000, Loss: 0.007419853005558252\n",
      "Epoch 871/1000, Loss: 0.007385813631117344\n",
      "Epoch 881/1000, Loss: 0.0073522902093827724\n",
      "Epoch 891/1000, Loss: 0.0073192669078707695\n",
      "Epoch 901/1000, Loss: 0.007286733947694302\n",
      "Epoch 911/1000, Loss: 0.007254681084305048\n",
      "Epoch 921/1000, Loss: 0.007223097141832113\n",
      "Epoch 931/1000, Loss: 0.007191970478743315\n",
      "Epoch 941/1000, Loss: 0.00716129457578063\n",
      "Epoch 951/1000, Loss: 0.007131059654057026\n",
      "Epoch 961/1000, Loss: 0.007101255469024181\n",
      "Epoch 971/1000, Loss: 0.007071875501424074\n",
      "Epoch 981/1000, Loss: 0.007042909041047096\n",
      "Epoch 991/1000, Loss: 0.007014349102973938\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "y_train = pd.get_dummies(y_train).values\n",
    "y_test = pd.get_dummies(y_test).values\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 1000\n",
    "batch_size = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1343\n",
      "           1       0.96      0.98      0.97      1600\n",
      "           2       0.95      0.93      0.94      1380\n",
      "           3       0.94      0.92      0.93      1433\n",
      "           4       0.93      0.94      0.94      1295\n",
      "           5       0.94      0.93      0.93      1273\n",
      "           6       0.95      0.97      0.96      1396\n",
      "           7       0.95      0.96      0.95      1503\n",
      "           8       0.94      0.94      0.94      1357\n",
      "           9       0.94      0.93      0.93      1420\n",
      "\n",
      "    accuracy                           0.95     14000\n",
      "   macro avg       0.95      0.95      0.95     14000\n",
      "weighted avg       0.95      0.95      0.95     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "outputs = model(X_test)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(classification_report(torch.argmax(y_test, 1).cpu().numpy(), predicted.cpu().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
